{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96ea2ff4-39d2-46bd-ab0b-5e1e7ad31772",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from smotdm.renderer.matplotlib import SceneRenderer\n",
    "from smotdm.data.motion import MotionLoader\n",
    "from smotdm.rifke import rifke_to_joints\n",
    "from smplx import SMPLX\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "INTERX_DATASET_FILE = \"deps/interx/dataset_tiny.h5\"\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "renderer = SceneRenderer(\n",
    "    colors1=(\"red\", \"red\", \"red\", \"red\", \"red\"),\n",
    "    colors2=(\"black\", \"black\", \"black\", \"black\", \"black\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "227d09df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from smotdm.rifke import joints_to_rifke, ungroup\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_joints(smplx_params):\n",
    "    output = smplx_model(\n",
    "        **smplx_params,\n",
    "    )\n",
    "\n",
    "    return torch.matmul(\n",
    "        output.joints,\n",
    "        torch.tensor(\n",
    "            [[1.0, 0.0, 0.0], [0.0, 0.0, 1.0], [0.0, 1.0, 0.0]],\n",
    "            device=device,\n",
    "        ),\n",
    "    )[:, : smplx_model.NUM_JOINTS, :]\n",
    "\n",
    "\n",
    "P1_smplx = np.load(\"deps/interx/motions/G001T000A001R005/P1.npz\")\n",
    "P2_smplx = np.load(\"deps/interx/motions/G001T000A001R005/P2.npz\")\n",
    "\n",
    "smplx_model = SMPLX(\n",
    "    model_path=\"deps/smplx/SMPLX_NEUTRAL.npz\",\n",
    "    num_betas=10,\n",
    "    use_pca=False,\n",
    "    use_face_contour=True,\n",
    "    batch_size=P1_smplx[\"pose_body\"].shape[0],\n",
    ").to(device)\n",
    "\n",
    "# difference_in_transl = torch.tensor(P2_smplx[\"trans\"]).to(device) - torch.tensor(\n",
    "#     P1_smplx[\"trans\"][0]\n",
    "# ).to(device)\n",
    "\n",
    "j1, j2 = (\n",
    "    get_joints(\n",
    "        {\n",
    "            \"body_pose\": torch.tensor(P1_smplx[\"pose_body\"]).to(device),\n",
    "            \"left_hand_pose\": torch.tensor(P1_smplx[\"pose_lhand\"]).to(device),\n",
    "            \"right_hand_pose\": torch.tensor(P1_smplx[\"pose_rhand\"]).to(device),\n",
    "            \"transl\": torch.tensor(P1_smplx[\"trans\"]).to(device),\n",
    "            \"global_orient\": torch.tensor(P1_smplx[\"root_orient\"]).to(device),\n",
    "        }\n",
    "    ),\n",
    "    get_joints(\n",
    "        {\n",
    "            \"body_pose\": torch.tensor(P2_smplx[\"pose_body\"]).to(device),\n",
    "            \"left_hand_pose\": torch.tensor(P2_smplx[\"pose_lhand\"]).to(device),\n",
    "            \"right_hand_pose\": torch.tensor(P2_smplx[\"pose_rhand\"]).to(device),\n",
    "            \"transl\": torch.tensor(P2_smplx[\"trans\"] - P1_smplx[\"trans\"]).to(device),\n",
    "            \"global_orient\": torch.tensor(P2_smplx[\"root_orient\"]).to(device),\n",
    "        }\n",
    "    ),\n",
    ")\n",
    "\n",
    "reactor_feats, translation, angles = joints_to_rifke(j1)\n",
    "actor_feats, _, _ = joints_to_rifke(j2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038fbaaf-4d07-4a9e-a3c3-af376e966a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loader = MotionLoader(INTERX_DATASET_FILE, fps=20.0)\n",
    "# sample1 = loader(\"G001T000A001R005\", 0, 0.0, 27.0)\n",
    "# sample2 = loader(\"G001T000A001R005\", 1, 0.0, 27.0)\n",
    "# motion1 = sample1[\"x\"]\n",
    "# motion2 = sample2[\"x\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e197598e-be9c-4a49-867e-d3cf0438c6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "renderer.render(\n",
    "    rifke_to_joints(reactor_feats).detach().cpu().numpy(),\n",
    "    rifke_to_joints(actor_feats).detach().cpu().numpy(),\n",
    "    output=\"test_recons.mp4\",\n",
    ")\n",
    "\n",
    "renderer.render(\n",
    "    j1.detach().cpu().numpy(),\n",
    "    j2.detach().cpu().numpy(),\n",
    "    output=\"test.mp4\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
